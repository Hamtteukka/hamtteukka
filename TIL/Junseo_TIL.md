# 1월 13일 TIL 

## 운영 체제

> 시스템 콜이 무엇인지 설명해 주세요.

운영체제는 커널 모드와 사용자 모드로 나뉘어 구동되며, 커널 모드에서만 메모리 등의 자원을 직접 조작하고, 하드웨어를 제어할 수 있기 때문에, 커널 모드로의 전환이 필요하다. 즉, 시스템 콜은 응용프로그램이 **커널이 제공하는 서비스를 이용하기 위한 인터페이스** 이다. 

**시스템콜은 커널 영역의 기능을 사용자 모드가 가용 가능하게, 즉 프로세스가 하드웨어에 접근해서 필요한 기능을 할 수 있게 해준다.**  

- 즉, 응용프로그램은 시스템 콜을 사용해서 원하는 기능을 수행할 수 있다.
- 보통 직접적으로 시스템 콜을 사용하기 보다는 API를 통해 사용하게 된다.

> 우리가 사용하는 시스템 콜의 예시를 들어주세요.

File I/O의 open, read, write, close 등이 있다. 예를 들어, read의 경우 하드웨어 메모리에 존재하는 특정 파일에 접근해서 파일을 읽을 준비를 하는 일련의 과정이 커널 모드에서 수행되게 된다. 이외에도 python의 sys, time 등의 함수 역시 시스템 콜의 예시로 들 수 있다. 

> 시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.

1. **사용자 프로그램 실행** 
    1. 먼저, 사용자가 작성한 프로그램이 사용자 모드에서 실행된다. 
2. **시스템 콜 호출**
    1. 프로그램이 운영체제의 특정 기능을 사용해야 할 때, 그 기능을 호출하는데 사용되는 함수 또는 명령을 호출한다. 이것이 바로 시스템 콜이다. 
        1. 예를 들어, 파일을 열고 읽는 작업을 해야 할 때, 사용자 프로그램은 파일 관련 시스템 콜을 호출한다. 
3. **사용자 모드에서 커널 모드로 전환**
    1. 시스템 콜 호출이 발생하면, 프로그램은 현재 실행 중인 사용자 모드에서 커널 모드로 전환된다. 커널 모드에서만 운영 체제의 핵심 기능과 하드웨어 자원에 접근할 수 있기 때문이다.
4. **요청 분석 및 처리**
    1. 커널은 내부적으로 시스템 콜 각각의 서비스 루틴에 대응되는 인덱스 테이블을 지니고 있고, 시스템 콜이 호출되면 이에 대응되는 인덱스를 참조하여 서비스 루틴을 수행한다. 
        1. 예를 들어, 파일 열기 요청의 경우 해당 파일을 찾아서 열기 작업을 수행한다. 
5. **작업 수행 및 결과 반환**
    1. 운영체제는 요청된 작업을 수행하고, 결과를 메모리에 저장하거나 레지스터에 반환한다. 
        1. 예를 들어, 파일을 읽는 작업의 경우 파일 내용을 메모리에 읽어온다. 
6. **커널 모드에서 사용자 모드로 전환**
    1. 요청된 작업이 완료되면, 운영체제는 다시 사용자 모드로 전환한다.
        1. 이제 프로그램은 작업 결과를 받아 사용자 모드에서 필요한 작업을 계속할 수 있다. 
7. **프로그램 실행 재개**
    1. 프로그램은 이제 시스템 콜 이후부터 다음 작업을 계속 수행한다. 필요한 결과를 받아 사용자 모드에서 다양한 작업을 진행할 수 있다.

> 시스템 콜의 유형에 대해 설명해 주세요.

**프로세스 제어**

- 프로세스 실행, 생성, 대기 등
- **종류**
    - fork() : 새로운 프로세스 생성
    - exec() : 새로운 프로그램 실행
    - exit() : 현재 프로세스 종료
    - wait() : 자식 프로세스가 종료될 때 까지 대기

**파일 조작**

- 파일 열기, 읽기, 쓰기 등
- **종류**
    - open() : 파일 열기
    - read()
    - write()
    - close()

**장치 관리**

- 디바이스 부착, 분리, 읽기, 쓰기 등
- **종류**
    - read() : 장치 읽기
    - write() : 장치 쓰기
    - ioctl() : 장치 제어

**정보 유지**

- 시간, 날짜 설정 등
- **종류**
    - getpid() : 현재 프로세스 ID 가져오기
    - alarm()  : 지정한 시간 후에 알람 시그널을 보내는 타이머를 설정
    - sleep() : 현재 프로세스를 지정한 동안 멈춤

**통신**

- 통신 연결 생성, 제거, 상태 정보 전달 등
- **종류**
    - pipe() : 두 프로세스 간에 단방향 통신 파이프를 생성
    - shm_open() : 공유 메모리 객체를 생성하거나 열기
    - mmap() : 파일의 내용을 메모리에 매핑하여 읽거나 쓸 수 있도록 변경

**보호**

- 파일 및 디렉터리의 접근 권한과 소유자 정보를 관리 등
- **종류**
    - chmod() : 파일 또는 디렉터리의 권한 변경
    - umask() : 새로운 파일 생성 시의 기본 권한 제한 설정
    - chown() : 파일 또는 디렉터리의 소유자와 그룹 소유자 변경


> 운영체제의 Dual Mode 에 대해 설명해 주세요.

Dual Mode는 OS를 보호하고 시스템 자원에 대한 안전한 접근을 보장하기 위해, **사용자 모드와 커널 모드로 나누는 기법**이다. 

사용자 프로세스는 제한된 권한을 가지며, 하드웨어 자원에 직접 접근할 수 없다. 자원에 접근하려면 시스템 콜을 통해 커널 프로세스에 요청해야 하며, 이 과정에서 **사용자 모드에서 커널 모드로 전환**이 이루어진다. 

**커널 모드**

운영체제의 핵심인 커널 코드가 실행 되는 상태이다. 커널은 운영체제의 핵심 기능을 수행하며 하드웨어 리소스에 접근하고 관리할 수 있는 권한을 가진다. 커널 모드에서 실행되는 코드는 시스템의 모든 자원에 접근하여 제어할 수 있으므로, 시스템 콜 및 운영체제의 서비스를 제공한다. 

**사용자 모드**

사용자 모드는 일반 응용 프로그램이 실행되는 상태이다. 이 모드에서 실행되는 프로그램은 자신의 주소 공간 내에서만 작동하며, 하드웨어 리소스에 직접적인 접근이 허용되지 않는다. 즉, 사용자 모드에서는 응용 프로그램이 제한된 권한을 가지며, 시스템 리소스에 대한 직접적인 제어는 불가능하다.

> 왜 유저모드와 커널모드를 구분해야 하나요?

사용자 프로세스가 항상 시스템 자원에 직접 접근 가능한 커널 모드에서 실행된다면, 시스템에 장애를 일으킬 수 있는 위험이 따른다. 이러한 위험을 방지하기 위해, 운영체제는 상대적으로 안전한 사용자 모드에서 프로그램을 실행한다. 

> 서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?

통상적으로 시스템 콜은 여러 종류의 기능으로 나뉘어져 있으며, 각 시스템 콜에는 번호가 할당된다. **System call Interface는 이러한 번호에 따라 인덱스 테이블을 관리하고 서로 다른 시스템 콜을 구분**할 수 있다. 

일부 운영 체제에서는 지정된 함수의 이름이 운영체제 내부에서 시스템 콜 번호로 변환되어 호출하는 과정에서 시스템 콜을 구분하여 실행한다. 

위 두 방법 중 하나 또는 둘을 조합하여 시스템 콜을 구분하고 처리한다.

> 인터럽트가 무엇인지 설명해 주세요.

프로세스 실행 도중 예기치 않은 상황이 발생할 때, 발생한 상황을 처리한 후 실행중인 작업으로 복귀하는 것을 말한다. 

**내부 인터럽트**

- 하드웨어 고장
    - 컴퓨터 고장
    - 데이터 전달 과정에서의 비트 오류
    - 전원이 나간 경우
- 실행할 수 없는 명령어
    - 기억 장치에서 인출한 명령어의 비트 패턴이 정의되어 있지 않은 경우
- 명령어 실행 오류
    - 나누기 0을 하는 경우
- 사용 권한 위배
    - 사용자가 운영체제만 사용할 수 있는 자원에 액세스 하는 경우

**외부 인터럽트**

- 외부 인터럽트는 주로 **입출력장치**에 의해 발생된다.
    - **타이머 인터럽트**
        - 타이머가 일정한 시간 간격으로 중앙처리장치에게 인터럽트를 요청
    - **입출력 인터럽트**
        - 속도가 느린 입출력 장치가 입출력 준비가 완료되었음을 알리기 위해 인터럽트를 요청


> 인터럽트는 어떻게 처리하나요?

요청 → 중단 → 보관 → 인터럽트 처리 → 재개

- **인터럽트 요청**
- **프로그램 실행 중단**
    - 현재 실행 중이던 Micro Operation 까지 수행
- **현재 실행 중인 프로그램 상태 보관**
    - PCB (Process Control Block), PC (Program Counter) 저장
- **인터럽트 원인 판별**
    - 인터럽트를 요청한 장치를 식별 → 인터럽트 원인을 파악
    - Interrupt Vector 테이블을 참조하여 호출할 ISR (인터럽트 서비스 루틴) 주소 값을 얻음
- **ISR (인터럽트 서비스 루틴) 처리**
    - 실질적인 인터럽트 처리 작업을 한다.
    - 서비스 루틴 수행 중, 우선순위가 더 높은 인터럽트가 발생하면 재귀적으로 1 ~ 5 과정을 수행한다.
    - 인터럽트 서비스 루틴을 실행할 때 인터럽트 플래그를 0으로 하면 인터럽트 발생을 방지할 수 있다.
- **상태 복구**
    - 상태 복구 명령어가 실행되면, 저장해 둔 PC를 다시 복원하여 이전 실행 위치로 복원한다.
- **중단된 프로그램 실행 재개**
    - PCB의 값을 이용하여 이전에 수행 중이던 프로그램을 재개한다.


> Polling 방식에 대해 설명해 주세요.

CPU가 작업을 진행하다 입출력 명령을 만나면 직접 입출력 장치에서 데이터를 가져오는 방식이다. CPU가 직접 일을 하기 때문에 입출력을 하는 동안 다른 일은 못한다. 따라서 입출력이 처리되는 동안 기다려야 하는데 시간이 오래 걸리며 작업 효율이 떨어져 현재는 사용하지 않는다. 

또한 정해진 시간이나 주기적으로 체크하는 방식으로 과거에는 작업 개수가 적었을 때 가능했던 방식이 오늘날 다양한 프로세스 처리에는 알맞지 않다. 

- **인터럽트와의 비교**
    - 어떠한 주변 장치들의 입출력이나 하드웨어 문제, 프로그램에서 예외가 발생했을 때 CPU에게 이를 알려주는 방식.

> HW / SW 인터럽트에 대해 설명해 주세요.

**HW 인터럽트**

- 하드웨어 인터럽트는 주로 하드웨어 장치에서 발생하는 이벤트로, 외부에서 발생한 신호에 의해 컴퓨터 시스템의 CPU에 전달된다.
- 이러한 인터럽트는 하드웨어 장치의 상태 변화를 나타내며, 예를 들어 데이터 전송 완료, 타이머 만료, 키보드 입력 등이 해당한다.
- 하드웨어 인터럽트는 주로 입출력 장치와의 상호 작용에 사용되며, 장치의 상태 변화를 즉시 처리할 수 있도록 한다.

**SW 인터럽트**

- 소프트웨어 인터럽트는 주로 프로그램 내에서 발생하는 이벤트로, CPU가 현재 실행 중인 명령어에 의해 생성된다.
- 예를 들어, 프로그램이 시스템 콜을 호출하거나 예외상황이 발생할 때 소프트웨어 인터럽트가 발생한다.
- 소프트웨어 인터럽트는 주로 프로세스 관리, 예외 처리, 시스템 호출 등과 관련된 작업에 사용된다.

> 동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?

**인터럽트 우선 순위**

- 각 인터럽트에는 우선 순위가 할당되어 있고, 더 높은 우선순위를 갖는 인터럽트가 먼저 처리 된다.
- 이는 하드웨어나 소프트웨어에서 지정된 방식으로 우선 순위가 관리된다.
- 따라서 우선 순위가 높은 인터럽트가 먼저 처리 되고, 그 후에 낮은 우선 순위의 인터럽트가 처리 된다.

**인터럽트 마스킹**

- 시스템은 한 번에 하나의 인터럽트만 처리할 수 있기 때문에, 다중 인터럽트가 발생하면 다른 인터럽트를 일시적으로 마스크하여 처리 중인 인터럽트를 완료한 후에 처리할 수 있다.
- 이를 통해 다중 인터럽트에 대한 우선 순위나 순서를 관리할 수 있다.

**인터럽트 대기 큐**

- 시스템은 인터럽트를 대기하는 큐를 유지하여 동시에 발생한 인터럽트를 처리하는 방식이다.
- 인터럽트가 발생하면 해당 인터럽트를 큐에 추가하고, 우선 순위에 따라 큐에서 처리된다.
- 이 방식은 다중 인터럽트를 효율적으로 처리할 수 있도록 한다.


## CKA
<aside>
❗**YAML 말고 명령어로 pod 만들기**

</aside>

```
kubectl run nginx --image=nginx
```

<aside>
❗**명령어로 pods가 위치되어있는 nodes 보기**

</aside>

describe 해서 봐도 된된다

```
kubectl get pods -o wide
```

하면 쭉 볼 수 있음 

<aside>
❗**컨테이너 갯수 보기**

</aside>

```
kubectl get pods
```

해서 READY에 있는 뒤에 있는 수가 컨테이너 갯수

<aside>
❗**READY 컬럼이 의미하는 것**

</aside>

Running containers in pod / total containers in pod

<aside>
❗**yaml 파일로 생성하는 쉬운 방법**

</aside>

```
kubectl run redis --image=redis123 --dry-run=client -o yaml
```

- **`-dry-run=client`**:
- 실제로 리소스를 클러스터에 적용하지 않고, 생성될 리소스의 YAML만 출력합니다.
- 리소스가 올바르게 생성될지 시뮬레이션하는 데 사용됩니다.

<aside>
❗**pod 수정하기**

</aside>

```
kubectl edit
```

```
cat redis.yml
vi redis.yml
```


<hr>

# 0114 TIL


## 화상 회의를 구현하는 방법 ( 1 : 1 )

[[WebRTC] 화상 회의를 구현하는 방법 (1:1)](https://hwanheejung.tistory.com/47)

### 프롤로그

채팅을 구현하기 위해서는 지속적인 연결을 유지하는 웹 소켓을 사용한다. 

웹 소켓에서는 A가 B에게 채팅을 보낼 때 두 사용자가 직접 연결되어 있는 것이 아니라, 서버의 중개를 통해 대화를 나눈다.

즉, A가 채팅을 보내면, 서버로 전송되고, 서버는 해당 채팅방을 구독하고 있는 사용자들에게 메시지를 보내주는 것이다. 이 방식은 클라이언트의 수가 늘어날 수록 서버에게 큰 부담이 된다. 간단한 텍스트를 보낼 때는 오버헤드가 작을 수도 있지만, 주고 받는 데이터가 영상이나 오디오처럼 용량이 크다면 서버의 부담이 엄청날 것이다. 

Web RTC는 서버의 중개 없이 클라이언트끼리 직접 소통한다. 이로 인해 서버는 데이터를 처리할 필요가 없어지고, 클라이언트끼리 직접 소통하다 보니 빠르게 소통할 수 있게된다. 

### WebRTC 동작 원리

1. **Signaling**
    1. 두 피어가 서로 통신을 시작하기 전에 서로의 정보를 교환할 필요가 있다. 서버가 이를 중계해주는데, 이를 signaling server라고 한다. 
    2. 즉, 브라우저는 서로가 무엇으로 어떻게 소통할 수 있는지 signaling server를 통해 정보를 교환한다. 
    3. signaling 자체는 WebRTC의 일부가 아니기 때문에 웹소켓이나 HTTP 등 외부 protocol을 사용해서 구현해야 한다. 
2. **ICE**
    1. 네트워크 경로를 설정하기 위해 사용되는 protocol
    2. 여러 종류의 candidate를 사용해서 연결을 시도한다. 각 ICE  Candidate에는 클라이언트들이 각각 소통에 사용할 수 있는 네트워크 경로들의 정보가 담겨 있다. 
    3. **Host Candidate**
        1. 같은 로컬 네트워크에 속한 경우이며, 각 기기의 네트워크 내부용 주소인 private IP 주소와 포트 번호를 교환한다. 
    4. **Server Reflexive Candidate**
        1. NAT 뒤에 있는 경우이며, STUN 서버를 사용하여 public IP 주소와 포트 번호를 알아내어 ICE Candidate으로 등록한다. 
        - **NAT**
            
            내부 네트워크의 private IP 주소를 public IP 주소로 변환하는 방법으로, NAT를 통해 외부 네트워크와 통신할 수 있게 된다. 
            
        - **STUN (Session Traversal Utilities for NAT)**
            
            상대방에게 알려줄 나의 주소를 알아내기 위해 STUN 서버를 사용한다. NAT 뒤에 있는 기기가 STUN 서버에 요청을 보내면, 응답으로 public IP 주소와 포트 번호를 알려준다. 
            
    5. **Relay Candidate**
        1. 네트워크 환경이 복잡하거나 방화벽 등에 의해 P2P 통신이 제한된 경우 TURN 서버를 사용한다. 이때 추가적인 경로를 거치므로 지연 시간 증가와 비용이 발생한다. 
        - **TURN 서버**
            
            만약 STUN 서버를 통해서도 직접 연결이 불가능하면, 클라이언트는 TURN 서버에 자신을 등록하고, 데이터 전송 시 TURN 서버가 각 클라이언트로 데이터를 중계한다. 
            
        
3. **SDP**
    1. Peer 간의 연결 설정을 위해 사용하는 protocol로, ICE Candidate 정보를 SDP에 포함 시켜서 상대방에게 전달한다. 



## 다대다 화상회의: OpenVidu를 도입하기까지의 자료조사

[[WebRTC] 다대다 화상회의: OpenVidu를 도입하기까지의 자료조사](https://hwanheejung.tistory.com/48)



### 연결이 수립되기까지의 Flow



크게 **SDP Offer/Answer 과정**과 **ICE Candidate 교환 과정**으로 나눌 수 있다. 이 두 과정은 독립적, 병렬 적으로 일어난다.  그러니까 SDP offer/answer 과정이 진행되는 동안에도 ICE Candidate 정보를 교환해서 빠르게 P2P 연결이 수립된다. 

**SDP Offer / Answer 과정 (미디어 정보 교환하자!)**

1. Peer A는 카메라, 마이크 상태와 같은 **Media 정보를 등록**
2. 이 media 정보를 SDP에 담아 signaling server를 통해 Peer B에게 전달 - **Offer**
3. offer를 받은 Peer B는 마찬가지로 자신의 Media 정보를 **Answer**로 응답 


**ICE Candidate 교환 과정 ( 너 누구야 ? )**

1. Peer A는 STUN 서버 또는 TURN 서버를 통해 자신의 IP 주소와 포트 정보를 알아낸 후, ICE candidate 객체를 포함시켜 signaling server을 통해 Peer B에게 전달한다.
2. Peer B도 마찬가지로 자신의 ICE candidate 정보를 signaling server를 통해 Peer A에게 전달한다.
3. Peer A와 Peer B는 각각 받은 ICE candidate 정보를 이용하여 직접 연결을 시도한다. 
4. 연결 성공


**Signaling Server의 역할**

브라우저끼리 통신을 하려면 서로 누군지 알아야 하는데, 그 과정을 signaling server가 중계해주는 것이다. 즉, Signaling server는 단순히 offer, answer, 그리고 ICE candidate **정보를 교환하는 중계 역할만 하고 이 과정이 끝나면 더 이상 관여하지 않고 브라우저끼리 소통하게 된다.** 


## 다대다 화상회의는 ?

**Mesh**

모든 참가자가 서로 직접 연결된다면 (Mesh 방식) 몇십 명, 몇백 명 정도를 감당하기에는 무리가 있어 보인다. 간단하게 생각해 봐도, 4명이 화상회의를 한다고 했을 때, A-B, A-C, A-D, B-C, C-D 즉 6번의 연결 수립이 이루어져야 한다. 참여자가 늘어날수록 연결의 수는 기하급수적으로 늘어나게 된다. 

즉, 다대다 통신을 P2P 통신으로 구현할 경우 클라이언트에 큰 부담이 될 것이다. 그래서 나온 것이 SFU, MCU 방식의 **media server** 이다. 

**SFU (Selective forwarding Unit)**

5명의 참가자가 있다고 했을 때, A는 자신의 영상 데이터를 B,C,D,E 에게 모두 전송하는 것이 아니라 MEDIA 서버에만 전송한다. Media 서버는 A의 데이터를 B,C,D,E에게 뿌린다. 즉 1명당 1개의 uplink (클라 → 서버) , 4개의 downlink (서버 → 클라) 를 가지게 된다. 

즉, 브라우저끼리의 P2P가 아니라 서버-클라이언트 간의 peer 연결이다. Mesh 방식과 비교하면 downlink의 수는 N-1로 같지만, uplink의 값은 1개로 줄었다. 

일부 참가자는 uplink가 필요 없을 수도 있다. 라이브 방송과 같이 publisher가 1명, subscriber가 N명인 1:N 통신인 경우, publisher는 영상 데이터를 media server에 한 번만 업로드하고 N명의 subscriber는 서버로부터 수신하는 경우 SFU를 사용하면 연결 수가 확실히 줄어든다. 

또는 회의에서 발표하는 그룹과 듣는 그룹이 정해져 있는 경우와 같이 데이터를 송출하는 그룹(N명)과 수신하는 그룹(M명)이 명확하게 분리되어 있는 경우도 SFU 방식이 적합하다. 

**MCU (Multipoint Control Unit)**

MCU에서는 Media 서버가 모든 영상 데이터를 받아서 하나로 합치고, 이를 모든 클라이언트로 전송한다. 예를 들어 5명의 화상회의에서 중앙 서버는 A를 제외한 4명의 영상, 음성 데이터를 하나로 합쳐서 A에게 보낸다. 

나머지 참가자들에게도 동일하게 적용되어 1명당 1개의 uplink, 1개의 downlink를 가지게 된다. 이 방식은 서버에 더 많은 부하를 주지만 클라이언트는 하나의 스트림만 전송, 수신하므로 부하가 확실히 줄어든다. 

> **하지만 애초에 WebRTC가 나온 이유가 서버의 부하를 줄이고 실시간성을 높이기 위함인데, MCU 방식은 일반적인 서버 기반 통신과 다를 것이 없는게 아닐까?**
> 

아니다. WebRTC의 MCU 방식에서도 서버에 부하가 걸리지만, 프로토콜 최적화와 QoS 관리, 그리고 보안 측면 덕분에 더 효율적으로 관리할 수 있다. 서버에 부하가 크긴 하지만, 그래도 WebRTC를 안 쓰는 것보단 쓰는게 훨씬 더 효율적이다. 

**Media Server가 하는 일** 

1. **Group Communications**
    1. 위에서 설명한 것처럼 한 peer가 생성한 미디어 스트림을 여러 subscriber들에게 전달한다. SFU, MCU 역할을 하는 것이다. 
2. **Mixing**
    1. 여러 개로 들어오는 미디어 스트림을 하나의 화면에 합성해서 각 참가자가 N개 비디오 화면을 동시에 볼 수 있게 하고, 여러 참가자의 목소리를 하나의 오디오 스트림으로 mixing 해서 동시에 들을 수 있게 하는 것을 말한다. 
3. **Transcoding**
    1. 클라이언트 간에 호환이 되지 않을 때, codec과 format을 실시간으로 변환하는 작업을 말한다. 예를 들어 한 클라이언트가 H.264 비디오 codec을 사용하고 다른 클라이언트가 VP8 비디오 codec을 사용한다면, 서버는 H.264 스트림을 VP8로 변환하여 호환성을 유지한다. 
4. **Recording**
    1. 클라이언트 간에 교환되는 미디어를 저장한다. 예를 들어 회의를 녹화해서 나중에 또 볼 수 있게 한다. 

---


## Kurento

media server의 일종. 무료이다. docs가 정말 자세하다. MCU, SFU를 모두 지원하며, 클라이언트 API를 제공한다. 

[Introduction to Kurento — Kurento 7.1 documentation](https://doc-kurento.readthedocs.io/en/latest/user/intro.html#why-a-webrtc-media-server)

**Distribution of Media and Application Services**

Kurento Media Server(KMS)는 여러 기기에서 배포, 확장, 분산될 수 있다. 하나의 애플리케이션이 여러 KMS를 호출할 수 있고, 반대로 하나의 KMS도 여러 애플리케이션의 요청을 처리할 수 있다.

**Application development**

개발자는 복잡한 KMS 내부를 신경 쓰지 않아도 된다. 모든 프레임워크에서 배포 가능하다.

**End-to-End Communication Capability**

Kurento는 미디어의 전송, encoding/decoding 및 클라이언트 장치에서의 렌더링 복잡성을 처리하지 않아도 되는 end-to-end 통신을 제공한다.

그러니까 개발자들이 WebRTC 기반의 SFU, MCU를 low level에서 개발하지 않아도 kurento를 사용해서 어느 정도 쉽게 구현할 수 있고, 추가적으로 다양한 기능들도 많이 지원한다.

그런데 kurento docs에 눈에 띄는 경고문이 있다.

!https://blog.kakaocdn.net/dn/GA1RI/btsIGl2wXTi/5iHri7xK5GFfWebDxRm3J0/img.png

초짜면 Openvidu를 써라는 것이다. 

## OpenVidu

Kurento 기반의 프레임워크이다. WebRTC를 사용하는 경우는 보통 화상 회의를 구현해야 하는 경우일텐데, 간단한 화상 회의를 구현해야 하는데 굳이 Kurento의 low level 코드를 만지지 않아도 된다. 

복잡한 기능을 개발해야 한다면 kurento를 써도 되는데, openvidu로도 충분히 많은 기능을 구현할 수 있기 때문에 kurento 공식 페이지에서도 openvidu를 추천한다. 

OpenVidu 페이지로 가봤더니 v3.0.0에 엄청난 변화가 생겼다. 내부 media server로 kurento를 버리고 mediasoup를 선택했고, livekit가 도입됐다. 하지만 문제는 Mediasoup는 node.js 환경에서 사용되도록 설계되었는데 우리는 spring을 사용하고 있다. 통합을 시도해 봤지만 쉽지 않았고, 그래서 kurento 기반의 v2.30.0 버전을 쓰기로 했다.


<hr>

# 0115 TIL

### OS

> 프로세스가 무엇인가요?


실행 중인 프로그램을 의미한다. 프로세스는 운영체제에 의해 관리되며, 독립적으로 실행되고 자원을 할당 받을 수 있는 단위이다. 운영체제는 프로세스들에게 적절히 자원들을 분배하여 여러가지 작업을 수행할 수 있게 한다. 


> 프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.

[👩‍💻 ‍완전히 정복하는 프로세스 vs 스레드 개념](https://inpa.tistory.com/entry/%F0%9F%91%A9%E2%80%8D%F0%9F%92%BB-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%E2%9A%94%EF%B8%8F-%EC%93%B0%EB%A0%88%EB%93%9C-%EC%B0%A8%EC%9D%B4#%EC%A0%95%EC%A0%81_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8_static_program)

프로세스는 실행 중인 프로그램을 의미하고, 독립된 메모리 공간을 가진다. 반면, 스레드는 프로세스 내에서 실행되는 실행 단위로, 프로세스의 자원을 공유하면서 동작한다. 

**프로세스**는 운영체제로부터 자원을 할당받은 **작업의 단위**이다. 스레드는 할당받은 자원을 이용하는 **실행 흐름의 단위**이다. 

**정적 프로그램**

**컴퓨터에서 실행 할 수 있는 파일**을 통칭한다. 단, 아직 **파일을 실행하지 않은 상태**이기 때문에 정적 프로그램을 줄여서 프로그램이라고 부른다. 즉, **코드 덩어리** 이다.

**프로세스**

**프로그램이 돌아가고 있는 상태**를 말한다. 즉, 컴퓨터에서 **작업** 중인 프로그램을 의미한다. 

| **프로그램** | **프로세스** |
| --- | --- |
| 어떤 작업을 하기 위해 실행할 수 있는 파일 | 실행되어 작업중인 컴퓨터 프로그램 |
| 파일이 저장 장치에 있지만 메모리에는 올라가 있지 않은 정적인 상태  | 메모리에 적재되고 CPU  자원을 할당받아 프로그램이 실행되고 있는 상태  |
| 쉽게 말해 그냥 코드 덩어리 | 그 코드 덩어리를 실행한 것 |

**스레드**

하나의 **프로세스 내에서 동시에 진행되는 작업 갈래, 흐름의 단위**를 말한다. 

- 비유
    
    크롬 브라우저가 실행되면 프로세스 하나가 생성된다. 그런데 우리는 브라우저에서 파일을 다운 받으며 온라인 쇼핑을 하면서 게임을 하기도 한다. 
    

즉, 하나의 프로세스 안에서 여러 작업들 흐름이 동시에 진행되기 때문에 가능한 것인데, 이러한 일련의 작업 흐름들을 스레드라고 하며 여러개가 있다면 이를 다중 스레드 라고 부른다. 

스레드 수가 많을 수록 당연히 프로그램 속도도 동시에 하는 작업이 많아져 성능이 올라간다. 

일반적으로 하나의 프로그램은 하나 이상의 프로세스를 가지고 있고, 하나의 프로세스는 반드시 하나 이상의 스레드를 갖는다. 즉, 프로세스를 생성하면 기본적으로 하나의 main 스레드가 생성된다. 

- 추가
    
    ### 프로세스 & 스레드의 메모리
    
    ---
    
    **프로세스의 자원 구조** 
    
    프로그램이 실행되어 프로세스가 만들어지면 다음 4가지의 메모리 영역으로 구성되어 할당받게 된다. 
    
    **코드 영역**
    
    프로그래머가 작성한 프로그램 함수들의 코드가 CPU가 해석 가능한 기계어 형태로 저장되어 있다. 
    
    **데이터 영역**
    
    코드가 실행되면서 사용하는 전역 변수나 각종 데이터 들이 모여있다. 데이터 영역은 .data, .rodata, .bss 영역으로 세분화 된다. 
    
    **스택 영역**
    
    지역 변수와 같은 호출한 함수가 종료되면 되돌아올 임시적인 자료를 저장하는 독립적인 공간이다. Stack은 함수의 호출과 함께 할당되며, 함수의 호출이 완료되면 소멸한다. stack 영역을 초과하면 stack overflow 에러가 발생한다. 
    
    **힙 영역**
    
    생성자, 인스턴스와 같은 동적으로 할당되는 데이터들을 위해 존재하는 공간이다. 사용자에 의해 메모리 공간이 동적으로 할당되고 해제된다. 
    
    코드와 데이터 영역은 선언할 때 그 크기가 결정되는 정적 영역이지만, 스택 영역과 힙영역은 프로세스가 실행되는 동안 크기가 늘어났다 줄어들기도 하는 동적 영역이다.
    
    **스레드의 자원 공유** 
    
    프로세스의 자원을 공유하면서 프로세스 실행 흐름의 일부가 된다. **스레드는 Stack만 할당 받아 복사하고 Code, Data, Heap은 프로세스 내의 다른 스레드 들과 공유**된다. 
    
    따라서 각각의 스레드는 별도의 stack을 가지고 있지만 heap 메모리는 고유하기 때문에 서로 다른 스레드에서 가져와 읽고 쓸 수 있게 된다. 
    
    
    ```
    stack은 함수 호출 시 전달되는 인자, 되돌아갈 주소값, 함수 내에서 선언하는 변수 등을 저장하는 메모리 공간이기 때문에, 독립적인 스택을 가졌다는 것은 독립적인 함수 호출이 가능하다 라는 의미이다. 그리고 독립적인 함수 호출이 가능하다는 것은 독립적인 실행 흐름이 추가된다는 말이다.
    즉, stack을 가짐으로써 스레드는 독립적인 실행 흐름을 가질 수 있게 되는 것이다.
    ```
    
    ```
    반면에 프로세스는 기본적으로 프로세스 끼리 다른 프로세스의 메모리에 직접 접근할 수는 없다.
    ```
    


> **PCB가 무엇인가요?**


운영체제에서 프로세스를 관리하기 위해 해당 프로세스의 상태 정보를 담고 있는 자료구조를 말한다. 

프로세스를 컨텍스트 스위칭 할 때 기존 프로세스의 상태를 어딘가에 저장해 둬야 다음에 똑같은 작업을 이어서 할 수 있을 것이고, 새로 해야 할 작업의 상태 또한 알아야 어디서부터 다시 작업을 시작할 지 결정할 수 있을 것이다. 즉. PCB는 프로세스 스케쥴링을 위해 프로세스에 관한 모든 정보를 저장하는 임시 저장소 이다. 

프로세스가 생성되면 **메모리에 해당 프로세스의 PCB가 함께 생성, 종료 시 삭제** 


> **그렇다면, 스레드는 PCB를 갖고 있을까요?**


PCB 처럼, TCB(스레드 제어 블록)이 있다. 각 스레드마다 운영체제에서 유지하는 스레드에 대한 정보를 담고 있는 자료구조이다. TCB는 PCB 안에 들어있다. 스레드의 상태 정보, 스레드 ID, 스레드 우선순위, 스케쥴링 정보 등 다양한 정보를 저장한다. TCB도 스레드가 생성될 때 운영 체제에 의해 생성되며, 스레드가 실행을 마치고 소멸 될 때 함께 소멸된다. 


> **리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?**


프로세스는 시스템 호출인 fork()를 통하여 생성이 됩니다. 또한 리눅스는 최초의 프로세스인 init을 갖고 있습니다. 스레드는 프로세스와 비슷한 양상으로 시스템 호출인 pthread_create()를 사용하여 새로운 스레드를 생성합니다.


> 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?

**[ 고아 프로세스 ]**

부모 프로세스가 자식 프로세스보다 먼저 종료되면 init 프로세스가 자식 프로세스의 새로운 부모 프로세스가 된다. 종료되는 프로세스가 발생할 때 커널은 이 프로세스가 누구의 부모 프로세스인지 확인한 후, 커널이 자식 프로세스의 부모 프로세스 ID를 1 (INIT 프로세스)로 바꿔준다. 

**[ 좀비 프로세스 ]**

자식 프로세스가 부모 프로세스 보다 먼저 종료되는 경우이다. 자식 프로세스가 EXIT 시스템 콜을 호출하면서 종료하면 이 프로세스에 관련된 모든 메모리와 리소스가 해제되어 다른 프로세스에서 사용할 수 있게 된다. 

자식 프로세스가 종료된 이후에 부모 프로세스가 자식 프로세스의 상태를 알고 싶을 수 있기 때문에 커널은 자식 프로세스가 종료되더라도 최소한의 정보를 가지고 있게 된다. 

최소한의 정보 : 프로세스 ID, 프로세스 종료 상태 등 


> **리눅스에서, 데몬프로세스에 대해 설명해 주세요.**


[데몬(daemon) 프로세스의 정의와 실행 방법](https://wildeveloperetrain.tistory.com/168)

**데몬(Daemon)**

정해진 일을 하는 프로세스다. 

Unix 운영체제에서 부팅 시 자동으로 켜져, 백그라운드에서 계속 실행되는 프로세스이다. 

데몬은 백그라운드 프로세스에 속하기 때문에 백그라운드 프로세스와 마찬가지로 TTY(터미널 장치)를 가지고 있지 않으며, 추가로 PPID(parent id)가 1이고, SID(session id) 역시 자신의 아이디와 같다는 특징이 있다. 

유닉스 (리눅스를 포함한) 운영체제에서 이름이 d로 끝나는 프로세스들이 대표적인 데몬 프로세스라고 볼 수 있다

ex) initd, httpd, nfsd, sshd, lpd, systemd, ftpd, syslogd 등이 있습니다.


> **리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.**


리눅스에서 프로세스 트리의 루트 노드는 init 프로세스이다. 

init 프로세스는 시스템 부팅 시에 가장 먼저 실행되는 프로세스로, 나머지 모든 프로세스는 init의 자손이거나 자식 프로세스라고 볼 수 있다. 



> **프로세스 주소공간에 대해 설명해 주세요.**


**코드 영역**

프로그래머가 작성한 프로그램 함수들의 코드가 CPU가 해석 가능한 기계어 형태로 저장되어 있다. 

**데이터 영역**

코드가 실행되면서 사용하는 전역 변수나 각종 데이터 들이 모여있다. 데이터 영역은 .data, .rodata, .bss 영역으로 세분화 된다. 

**스택 영역**

지역 변수와 같은 호출한 함수가 종료되면 되돌아올 임시적인 자료를 저장하는 독립적인 공간이다. Stack은 함수의 호출과 함께 할당되며, 함수의 호출이 완료되면 소멸한다. stack 영역을 초과하면 stack overflow 에러가 발생한다. 

- 지역 변수와 매개변수가 저장되는 영
- 메모리의 높은 주소에서 낮은 주소의 방향으로 할당된다.

**힙 영역**

생성자, 인스턴스와 같은 동적으로 할당되는 데이터들을 위해 존재하는 공간이다. 사용자에 의해 메모리 공간이 동적으로 할당되고 해제된다. 

- 런타임에 크기가 결정되는 영역이다.
- 메모리의 낮은 주소에서 높은 주소의 방향으로 할당된다.

코드와 데이터 영역은 선언할 때 그 크기가 결정되는 정적 영역이지만, 스택 영역과 힙영역은 프로세스가 실행되는 동안 크기가 늘어났다 줄어들기도 하는 동적 영역이다.


> **초기화 하지 않은 변수들은 어디에 저장될까요?**


전역변수랑 정적 변수가 초기화 되지 않았을 때 Data 영역에 BSS 세그먼트에 저장된다.

지역변수는 처리하는 함수의 스택에 저장된다. 



> **일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?**


- 스택과 힙 모두 디폴트 크기 값이 존재하며, 이는 **운영체제와 컴파일러에 따라 다를 수 있음**
- 스택의 경우, 윈도우에서는 1MB, 리눅스에서는 8MB가 기본 크기
- 힙의 경우, 1MB 또는 더 작은 크기를 기본 크기값부터 시작해, 동적 메모리 할당시 크기가 점점 증가함
- 힙의 크기는 물리적 리소스 또는 가용한 가상 메모리 주소 공간에 의해 제한됩니다. 즉, 이론적으로 32비트의 경우 2~3GB까지 제한되며, 64비트의 경우 거의 제한이 없다(16엑사바이트까지)고 할 수 있음

스택 영역의 크기는 컴파일 타임에 결정됩니다. 함수 호출이 발생하면 스택 프레임이 생성되어 스택 영역이 증가하고, 함수가 종료되면 스택 프레임이 제거되어 스택 영역이 감소합니다. 스택 오버플로우는 스택 영역의 크기가 프로세스에 할당된 스택 영역의 최대 크기를 초과할 때 발생합니다.

반면에 힙 영역의 크기는 런타임에 결정됩니다. 프로그램이 동적으로 메모리를 할당하거나 해제할 때마다 힙 영역의 크기가 변화합니다. 메모리 누수는 프로그램이 할당한 메모리를 제대로 해제하지 않아 힙 영역이 점차 증가하는 현상을 의미합니다.



> **Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?**


Stack 공간의 접근 속도가 Heap 공간보다 더 빠릅니다.
Stack은 정적 메모리 할당을 사용하며, 데이터가 연속된 메모리 블록에 저장되기 때문에 접근 속도가 빠릅니다.
반면, Heap은 동적 메모리 할당을 사용하며, 메모리 블록이 불연속적으로 분포되어 있어 접근 속도가 느립니다

스택 메모리는 LIFO(Last In First Out) 방식으로 관리되며, 메모리 할당과 해제가 상대적으로 빠릅니다. 스택 프레임이 생성되고 제거되는 것은 단순히 스택 포인터를 이동시키는 것이기 때문에, 이는 매우 빠른 연산입니다. 그러나 스택의 크기는 컴파일 타임에 결정되어 실행 중에는 변경할 수 없습니다.

반면에 힙 메모리는 동적으로 할당되고 해제되며, 메모리 관리가 복잡하고 시간이 더 많이 소요됩니다. 메모리 블록을 찾고, 할당하고, 해제하는 데 필요한 오버헤드가 있기 때문입니다. 그러나 힙의 크기는 유연하게 조절할 수 있어 필요에 따라 큰 데이터를 저장하는 데 사용할 수 있습니다.

따라서, 일반적으로 스택의 메모리 접근 속도는 힙보다 빠르다고 할 수 있지만, 실제 성능은 메모리를 어떻게 사용하느냐에 따라 크게 달라질 수 있습니다.

스택 할당이 힙할당보다 한참 싸고, 접근할때 인스트럭션도 덜 들어가고, 캐시히트 측면에서도 유리하다



> **다음과 같이 공간을 분할하는 이유가 있을까요?**


메모리를 분할하여 관리함으로써 각 영역에 맞는 메모리 관리 전략을 사용할 수 있고, 프로그램의 안정성과 효율성을 높일 수 있다.


> **스레드의 주소공간은 어떻게 구성되어 있을까요?**


각 스레드는 고유한 스택 영역을 가진다. 이 외에도 각 스레드는 **스레드 로컬 스토리지(TLS)**라는 고유한 데이터 영역을 가질 수 있다.  이는 각 스레드가 자신만의 전역 변수를 가질 수 있게 한다. 

그러나 코드영역, 데이터 영역, 그리고 힙 영역은 프로세스 내의 모든 스레드가 공유한다.

스레드의 주소 공간은 일부를 프로세스와 공유하면서도, 스레드마다 고유한 스택 영역과 TLS를 가지는 형태로 구성되어 있다. 이런 구조는 스레드가 독립적인 실행 흐름을 가질 수 있게 해주면서도, 필요한 데이터와 코드를 효율적 공유할 있게한다. 



> **"스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.**


스택 메모리 영역과 힙 메모리 영역은 자료구조와는 몇 가지 공통점이 있지만, 그렇다고 완전히 같은 개념은 아니다.

**스택 영역** : 이 영역은 자료구조의 스택처럼 후입선출 방식으로 동작한다. 함수가 호출되면, 해당 함수의 지역 변수와 매개변수, 반환 주소 등이 스택에 PUSH 되어 쌓이고, 함수가 종료되면 그 정보는 POP되어 제거된다. 

**힙 영역** : 이 영역은 자료구조의 힙과는 다르게 동작한다. 자료구조의 힙은 자료의 우선순위에 따라 정렬되는 반면, 메모리의 힙 영역은 동적으로 메모리를 할당하고 해제하는 역할을 한다. 프로그래머가 필요한 만큼 메모리를 할당하고 사용이 끝나면 해제할 수 있다. 이 과정은 자료구조의 힙과 직접적인 연관이 없다. 


> **IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?**


[[운영체제] 멀티 프로세스 환경에서 프로세스간 데이터는 어떻게 전달될까?](https://hyuuny.tistory.com/153)

[[Process & Thread] 프로세스간 통신(IPC, 공유메모리, 메시지전달)](https://karla.tistory.com/133)

별도의 공유 메모리가 생성된다. 


> **스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?**


**스택 영역의 크기**는 컴파일 때 결정되며, 운영체제나 컴파일러 설정에 따라 크기가 달라질 수 있다. 일반적으로 스택의 크기는 고정되어 있고 이 크기를 초과하면 ‘스택 오버플로우’라는 오류가 발생한다. 

**힙 영역의 크기**는 프로그램이 실행되는 동안 동적으로 변한다. 프로그램이 메모리를 필요로 할 때 운영체제에 요청하여 힙 영역에서 메모리를 할당 받는다. 사용이 끝난 메모리는 프로그램에 의해 해제 되어 다시 힙으로 반환된다. 

일반적으로 프로그램 사용자가 직접 스택과 힙의 크기를 수정하는 것은 불가능하다. 이들 영역의 크기는 운영체제의 메모리 관리 정책과 프로그램의 코드에 의해 결정되며, 사용자는 프로그램을 실행시키는 것으로 이들 영역을 사용한다. 

고급 사용자나 관리자는 운영체제의 설정을 통해 이러한 값들을 변경할 수 있다. 예를 들어, Linux에서는 'ulimit' 명령을 사용하여 프로세스의 스택 크기를 조정할 수 있다.



# 0116 TIL
# WAS와 웹 서버의 차이점은 무엇인가요?

---

**웹 서버**는 정적 컨텐츠(HTML, CSS, JS, 이미지 등)를 제공하는 역할을 수행한다. 동적 컨텐츠 요청 시 요청을 WAS로 전달할 수도 있다. 대표적인 웹 서버로는 Apache, Nginx 등이 있다.

**WAS**는 서블릿 컨테이너 기능을 제공하고, 동적 컨텐츠를 생성하거나, 애플리케이션 로직을 실행하는 데 특화되어 있다. 대표적인 WAS로는 Tomcat이 있다. 

정리하자면, **웹 서버**는 **정적 컨텐츠 제공**에 특화되어 있고, **WAS**는 **동적 컨텐츠 생성과 데이터 처리에 특화**되어 있다. 

<aside>
💡

**WAS도 정적 컨텐츠를 제공할 수 있는데 웹 서버가 따로 필요한 이유는 무엇일까요?**

</aside>

WAS가 너무 많은 역할을 담당하면 과부하가 될 수 있다. 웹 서버를 따로 분리하면 WAS는 중요한 애플리케이션 로직에 집중할 수 있으며, 웹 서버는 정적 리소스를 처리하면서 업무 분담이 가능하다. 

또한, 시스템 리소스를 효율적으로 관리할 수 있다. 정적 컨텐츠가 많이 사용되는 경우에는 웹 서버를 증설하고, 애플리케이션 자원이 많이 사용되면 WAS를 증설하면 된다. 이 외에도 로드 밸런싱을 하거나, 캐싱 및 압축, HTTPS 등을 웹서버에서 처리하도록 할 수 있다. 

## 좀 더 자세히

### Web Server

웹 서버는 클라이언트(사용자)가 브라우저 주소창에 url을 입력하여 어떤 페이지를 요청하면, http 요청을 받아 들여 HTML 문서와 같은 정적 콘텐츠를 사용자에게 전달해주는 역할을 한다. 

**웹 서버의 임무는 대표적으로 2가지로**

1. 단순히 저장된 웹 리소스들을 클라이언트로 전달하고, 클라이언트로부터 콘텐츠를 전달받아 저장하거나 처리한다. 
2. 사용자로부터 동적인 요청이 들어왔을 때, 해당 요청을 웹 서버 자체적으로 처리하기 어렵기 때문에 WAS에게 요청한다.
    1. 대표적인 웹 서버 종류 : Apache, Nginx, IIS (window 전용 웹 서버)

### WAS (Web Application Server)

WAS 또한 웹 서버와 동일하게 HTTP 기반으로 동작한다. 웹 서버가 할 수 있는 기능 대부분이 WAS에서도 처리가 가능하며, 비즈니스 로직 (서버 사이드 코드) 을 처리할 수 있어 사용자에게 동적인 콘텐츠를 전달할 수 있다. 주로 데베 서버와 같이 수행된다. 

### 차이점

기능적으로 동일한 영역도 있고 WAS가 웹 서버 기능의 많은 부분을 포함하여 수행하지만 사용의 ‘목적’이 다르다.

웹 서버는 정적인 데이터를 처리하는 서버이다. 이미지나 단순 HTML 같은 정적 리소스들을 전달하며, WAS만을 이용할 때 보다 빠르고 안정적으로 기능을 수행한다. 

반면 WAS는 동적인 데이터를 위주로 처리하는 서버이다. DB와 연결되어 사용자와 데이터를 주고받고, 조작이 필요한 경우 WAS를 활용한다. 

### 추가

웹 서버 만으로도 분명 동적인 요청 처리가 가능하다. 예를 들면 PHP의 경우 WAS 없이 아파치나 Nginx 만을 통해서 동적인 요청 처리가 가능하다. 그걸 가능 하게 해주는 것이 **CGI** 인데, **웹 서버에 별도로 저장**해줘야 한다. 

CGI는 이름 그대로 인터페이스로서, 웹 서버상에서 프로그램을 동작시키기 위한 방법을 정의한 프로그램 (또는 스크립트) 이다. 

**CGI**

동적 컨텐츠를 제공하기 위해 웹 서버 내에 프로그래밍 기능이 들어가는 방식이다. 

즉, PHP, Perl, Python 등의 언어들을 CGI를 구현해놓았기 때문에 아파치에서 다양한 언어로 짜인 각 프로그램을 실행할 수 있다. 예를들어, 아파치에게 PHP 모듈을 설치했을 경우, 요청이 왔을 때 아파치는 HTTP 헤더를 분석하고 파싱하여 PHP로 파라미터를 넘겨준다. 그러면 PHP에서는 파라미터를 받아 응답할 HTML 문서를 만들어 아파치에게 전달한다. 

HTML 문서를 전달받은 아파치는 CSS, JS, IMG 등 정적인 자원들과 함께 브라우저로 반환해준다. 하지만 이 역시 CGI 효율이 떨어진다. CGI 만으로는 규모가 큰 웹 서비스를 구현하기는 사실상 어렵다. 

많은 프로그래머들이 JAVA를 견고한 언어라고 평가하는 이유도 여기에 있다. 자바 서블릿은 CGI를 사용하지 않는다. 그래서 WAS에 대해 설명할 때 대표적으로 자바, 톰캣, 아파치로 예시를 든다. 

### References

https://yozm.wishket.com/magazine/detail/1780/

